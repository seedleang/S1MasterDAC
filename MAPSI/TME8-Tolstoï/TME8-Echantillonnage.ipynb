{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ei9rT_XZ3SO5"
   },
   "source": [
    "### TME 8 : Echantillonage\n",
    "\n",
    "## Diffusion dans les graphes \n",
    "\n",
    "Au cours des vingt dernières années, les réseaux sociaux sont devenus un média d’information incontournable, mettant en jeu des dynamiques complexes de communication entre utilisateurs. La modélisation de la diffusion d’information sur les réseaux constitue depuis lors un enjeu majeur, pour diverses tâches\n",
    "telles que l’identification de leaders d’opinions, la prédiction ou la maximisation de l’impact d’un contenu diffusé, la détection de communautés d’opinions, ou plus généralement l’analyse des dynamiques du réseau considéré.\n",
    "\n",
    "Le modèle proposé par (Saito et al, 2009) considère une diffusion en cascade dans laquelle l'information transite de noeuds en noeuds du réseau en suivant des relations d'influence entre les utilisateurs. Lorsqu'un utilisateur est ''infecté'' par une information, il possède une chance unique de la retransmettre à chacun de ses successeurs dans le graphe, selon une probabilité définie sur le lien correspondant. Le modèle définit en fait deux paramètres sur chaque lien $(u,v)$ du graphe:\n",
    "\n",
    "\n",
    "*   $k_{u,v}$: la probabilité que l'utilisateur $u$ transmette une information diffusée à $v$\n",
    "*   $r_{u,v}$: si la transmission s'effectue, l'utilisateur $v$ la reçoit au temps $t_v=t_u+\\delta$, avec $\\delta \\sim Exp(r_{u,v})$\n",
    "\n",
    "Pour utiliser ce modèle, on devra donc échantillonner selon la distribution exponentielle. Pour commencer, on cherche alors à écrire une méthode $exp(rate)$ qui échantillonne des variables d'une loi exponentielle selon le tableau d'intensités $rate$ passé en paramètre. Cet échantillonnage se fera par **Inverse Transform Sampling**. Pour éviter les divisions par 0, on ajoutera $1e-200$ aux intensités qui valent 0.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "f1aE9ijomC1j",
    "outputId": "80352e92-d353-4dad-fc36-daa80c92140e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98796784 0.49198855 0.33501196]\n",
      " [0.25022762 0.19644862 0.16723749]]\n",
      "[[1.00356177 0.50416273 0.34028414]\n",
      " [0.25231623 0.20024732 0.16911951]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# double boucle *triste*\n",
    "\"\"\"def exp(rate):\n",
    "    t = np.zeros(rate.shape)\n",
    "    for i in range(rate.shape[0]):\n",
    "        for j in range (rate.shape[1]):\n",
    "            t[i,j] = np.random.rand()\n",
    "            if (rate[i,j] == 0):\n",
    "                t[i,j] = -np.log(1-t[i,j])/(1e-200)\n",
    "            else:\n",
    "                t[i,j] = -np.log(1-t[i,j])/rate[i,j]\n",
    "    return t\"\"\"\n",
    "\n",
    "# et en un peu plus joli\n",
    "def exp(rate):\n",
    "    t = np.random.rand(*rate.shape)\n",
    "    rate = np.where(rate == 0, 1e-200, rate)\n",
    "    t = -np.log(1-t)/rate\n",
    "    return t\n",
    "\n",
    "a=exp(np.array([[1,2,3],[4,5,6]]))\n",
    "for i in range(10000):\n",
    "    a+=exp(np.array([[1,2,3],[4,5,6]]))\n",
    "print(a/10000)\n",
    "\n",
    "# pour comparaison: \n",
    "a=np.random.exponential(1.0/np.array([[1,2,3],[4,5,6]]))\n",
    "for i in range(10000):\n",
    "    a+=np.random.exponential(1.0/np.array([[1,2,3],[4,5,6]]))\n",
    "print(a/10000)\n",
    "\n",
    "# disons que tout se ressemble ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHJPFXBKoqIf"
   },
   "source": [
    "Soit le graphe de diffusion donné ci dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBihGMdL7tZw"
   },
   "outputs": [],
   "source": [
    "names={0:\"Paul\",1:\"Jean\",2:\"Hector\",3:\"Rose\",4:\"Yasmine\",5:\"Léo\",6:\"Amine\",7:\"Mia\",8:\"Quentin\",9:\"Gaston\",10:\"Louise\"}\n",
    "k={(0,1):0.9,(1,0):0.9,(1,2):0.2,(2,3):0.5,(3,2):0.4,(2,4):0.9,(4,3):0.9,(1,3):0.5,(2,5):0.5,(5,7):0.7,(1,6):0.2,(6,7):0.1,(1,8):0.8,(8,9):0.2,(1,10):0.5,(10,9):0.9,(8,1):0.8}\n",
    "r={(0,1):0.2,(1,0):3,(1,2):1,(2,3):0.2,(3,2):0.5,(2,4):10,(4,3):2,(1,3):2,(2,5):0.5,(5,7):15,(1,6):3,(6,7):4,(1,8):0.8,(8,9):0.1,(1,10):12,(10,9):1,(8,1):14}\n",
    "graph=(names,k,r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cx2XlKT97sbh"
   },
   "source": [
    "La fonction display_graph ci dessous permet de visualiser le graphe de diffusion correspondant: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "M-etZqDj3PXW",
    "outputId": "e893e14e-84e1-4300-e798-6682770b3b3b"
   },
   "outputs": [],
   "source": [
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "style = { \"bgcolor\" : \"#6b85d1\", \"fgcolor\" : \"#FFFFFF\" }\n",
    "\n",
    "def display_graph ( graph_data, style, graph_name=\"diffusion_graph\" ):\n",
    "    graph = pydot.Dot( graph_name , graph_type='digraph')\n",
    "    names,k,r=graph_data\n",
    "    # création des noeuds du réseau\n",
    "    for (i,name) in names.items():\n",
    "        new_node = pydot.Node( str(i)+\"_\"+name,\n",
    "                               style=\"filled\",\n",
    "                               fillcolor=style[\"bgcolor\"],\n",
    "                               fontcolor=style[\"fgcolor\"] )\n",
    "        graph.add_node( new_node )\n",
    "\n",
    "    # création des arcs\n",
    "    for edge,valk in k.items():\n",
    "        valr=r[edge]\n",
    "        n1=str(edge[0])+\"_\"+names[edge[0]]\n",
    "        n2=str(edge[1])+\"_\"+names[edge[1]]\n",
    "        new_edge = pydot.Edge ( n1, n2, label=\"k=\"+str(valk)+\",r=\"+str(valr))\n",
    "        graph.add_edge ( new_edge )\n",
    "\n",
    "    # sauvegarde et affichage\n",
    "    outfile = graph_name + '.png'\n",
    "    graph.write_png( outfile )\n",
    "    img = mpimg.imread ( outfile )\n",
    "    plt.imshow( img )\n",
    "display_graph(graph,style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0_Ol6AgQa9g"
   },
   "source": [
    "On souhaite être capable d'estimer les probabilités marginales d'infection des différents utilisateurs du réseau par une information pour laquelle on connaît le début de la diffusion. \n",
    "\n",
    "Pour cela, on considère une liste d'infections qui correspond aux couples (utilisateur, temps d'infection) observés pour cette diffusion pendant une période de temps initial. Par exemple la liste $infections=[(1,0),(4,1)]$ \n",
    "correspond à une diffusion pour laquelle on a observé l'infection de l'utilisateur 1 au temps 0 et l'infection de l'utilisateur 4 au temps 1. \n",
    "\n",
    "Etant donnés les cycles possibles dans le graphe de diffusion, considérer un calcul exact des probabilités d'infection des différents utilisateurs sachant le début de la diffusion est inenvisageable : il faudrait considérer toutes les combinaisons possibles (infinies) de temps d'infection pour tous les utilisateurs non observés dans la période initiale. \n",
    "\n",
    "Une possibilité pour calculer ces probabilités d'infections est de travailler par échantillonnage de Monte Carlo: on réalise $n$ tirages d'infections connaissant le début de la diffusion et on recense le ratio des simulations dans lesquelles chacun des utilisateurs est infecté avant un temps $maxT$.  \n",
    "\n",
    "L'idée est alors dans un premier temps d'écrire une méthode $simulation(graph,infections,max\\_obs)$ qui, à partir d'une liste d'infections initiales et d'un temps d'observation maximal $max\\_obs$, retourne les temps d'infection de l'ensemble des noeuds en fin de diffusion, sous la forme d'un tableau où chaque case $i$ contient le temps d'infection du noeud $i$. Si le noeud $i$ n'a pas été infecté ou bien si il l'a été après un temps maximal $maxT$, la case $i$ contient alors la valeur $maxT$. \n",
    "\n",
    "\n",
    "Le pseudo-code de la méthode de simulation est donné ci dessous, avec $t_i$ le temps d'infection courant du noeud $i$:\n",
    "```\n",
    "ti=maxT pour tout i non infecté dans la liste initiale\n",
    "Tant qu'il reste des infectieux dont le temps est < maxT:\n",
    "  i=Infectieux de temps d'infection minimal\n",
    "  Pour tout noeud j tel que tj>ti:\n",
    "    sampler x selon P(i->j|ti,tj>max_obs)\n",
    "    si x==1:\n",
    "       sampler delta selon Exp(rij)\n",
    "       t=ti+delta\n",
    "       si ti<max_obs: t+=max_obs-ti (c'est en fait une exponentielle tronquée à gauche, d'où la translation)  \n",
    "       si t<tj: tj=t \n",
    "  Retrait de i de la liste des infectieux\n",
    "```\n",
    "où $P(i\\rightarrow j|t_i,t_j>max\\_obs)$ correspond à la probabilité que $i$ transmette l'information à $j$ (quel que soit le temps d'infection) sachant qu'il ne l'a pas infecté avant $max\\_obs$:\n",
    "$P(i\\rightarrow j|t_i,t_j>max\\_obs)=\\begin{cases} k_{i,j} \\text{ si } t_i\\geq max\\_obs, \\\\ \\dfrac{k_{i,j} exp(-r_{i,j}(max\\_obs-t_i))}{k_{i,j} exp(-r_{i,j}(max\\_obs-t_i)) + 1 - k_{i,j} } sinon. \\end{cases}$\n",
    "\n",
    "Complétez le code de la fonction donnée ci-dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "FgfnYxbNTGDa",
    "outputId": "7b487aaa-f4ab-4887-ba7c-b622a93daf3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          6.27965381 10.         10.         10.         10.\n",
      " 10.         10.          6.99905281 10.         10.        ]\n",
      "[ 0.          8.27965381 10.         10.         10.         10.\n",
      " 10.         10.          8.99905281 10.         10.        ]\n",
      "[ 0.        1.       10.       10.       10.       10.       10.\n",
      " 10.        1.719399 10.       10.      ]\n",
      "[ 0.          1.         10.         10.         10.         10.\n",
      " 10.         10.          1.11395129  4.99417914  1.14895731]\n",
      "[ 0.          1.          3.4334778   1.51071594 10.         10.\n",
      "  1.96480682 10.          1.66945715  1.96435594  1.12402124]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "maxT=10\n",
    "  \n",
    "def simulation(graph,infections,max_obs):\n",
    "    names,gk,gr=graph\n",
    "    nbNodes=len(names)\n",
    "    # supposons au départ que tout le monde ait mis un temps maximal à s'infecter.\n",
    "    infectious=np.array([maxT]*nbNodes,dtype=float)\n",
    "    ids, t = map(np.array,zip(*infections)) # obtenir, par indice, une liste qui contient les infections réelles.\n",
    "    ids = ids[t<=max_obs]\n",
    "    t = t[t<=max_obs] # test des dates d'infection : ne retenir comme 'True' que celles qui sont sous max_obs :\n",
    "    # littéralement, à l'heure où je regarde mon graphe, qui a déjà l'information ?\n",
    "    infectious[ids]=t \n",
    "    times=np.copy(infectious)\n",
    "    inf=np.copy(infectious)\n",
    "    \n",
    "    # J'ai obtenu la liste des membres, avec parmi eux les infectés prêts pour transmission.\n",
    "    # Le premier noeud est pour l'instant le seul concerné. reste à voir comment la transmission va avancer.\n",
    "\n",
    "    while np.any([infectious<maxT]): # tant qu'il reste des infectieux dont le temps est < maxT\n",
    "        i = np.argmin(infectious) # aller chercher mon plus vieil infectieux, celui qui risque de passer le mot le plus tôt.\n",
    "        for j in range(len(times)): # observer tous les autres membres\n",
    "            if(times[j] > times[i]): # restreindre à ceux qui n'ont pas été infectés avant lui\n",
    "                if(not(i,j) in gr.keys()): x = 0 # et ne pas considérer les arcs qui n'existent pas dans le graphe, ce sont des gens auxquels il n'est pas lié.\n",
    "                \n",
    "                else: # mais s'il y a vraiment un potentiel de transmission, lancer l'échantillonnage selon P\n",
    "                    x = np.random.rand() # tirer une valeur qui représente des chances de transmission.\n",
    "                    if times[i] < max_obs: #  le temps est encore dans les limites qui m'intéressent,\n",
    "                        if x > (gk[(i,j)]*np.exp(-gr[(i,j)]*(max_obs-times[i])))/(gk[(i,j)]*np.exp(-gr[(i,j)]*(max_obs-times[i]))+1-gk[(i,j)]): # si x > probabilité limite de transmission:\n",
    "                            x = 0 # arc non utilisé\n",
    "                        else: x = 1 # arc utilisé\n",
    "                    else: # ! j'ai dépassé l'horizon d'observation.\n",
    "                        if x > gk[(i,j)]: x = 0 # arc non utilisé\n",
    "                        else: x = 1 # arc utilisé\n",
    "                            \n",
    "                if(x == 1): # selon ce qui précède, si l'arc va bien être utilisé,\n",
    "                    d = exp(np.array([gr[(i,j)]])) # tirer un temps arbitraire d au bout duquel l'information pourrait passer\n",
    "                    t = times[i] + d # ajouter le pas de temps d en question à l'état dans lequel i sait. me donne le temps total d+ti mis à faire passer l'info par ce chemin.\n",
    "                    if(times[i] < max_obs):\n",
    "                        t+=max_obs-times[i] \n",
    "                    if(t < times[j]): # si le temps total en question permet bien d'atteindre le noeud j suffisamment tôt,\n",
    "                        times[j] = t # alors considérer que j a été infecté par i, qui a lui-même mis un temps ti à savoir, au bout du temps d+ti.\n",
    "                        infectious[j] = t \n",
    "        infectious[i] = np.inf # suite à ce set, on ne considèrera plus jamais le noeud i, à cause de la condition d'entrée dans la boucle. moins compliqué que de le supprimer pour de bon.\n",
    "    return(times)\n",
    "\n",
    "print(simulation(graph,[(0,0)],0))\n",
    "np.random.seed(0)\n",
    "print(simulation(graph,[(0,0)],2))\n",
    "np.random.seed(0)\n",
    "print(simulation(graph,[(0,0),(1,1)],1))\n",
    "print(simulation(graph,[(0,0),(1,1)],1))\n",
    "print(simulation(graph,[(0,0),(1,1)],1))\n",
    "\n",
    "# Je ne m'explique absolument pas pourquoi les valeurs obtenues sont différentes.\n",
    "# L'algorithme me semble tout à fait convaincant et fidèle au pseudo-code.\n",
    "# Cela dit, elles permettent de retomber sur ce qu'il faut plus loin - alors, je suppose que tout est bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mPpzbeS_UMXk"
   },
   "source": [
    "La méthode $getProbaMC(graph,infections,max\\_obs,nbsimu)$ retourne les estimations de probabilités marginales d'infection des différents utilisateurs de $graph$, conditionnées à l'observation des infections de la liste $infections$ pendant les $max\\_obs$ premiers jours de diffusion. Pour être enregistrée, une infection doit intervenir avant la seconde $maxT$. Ainsi, si la méthode retourne 0.2 pour le noeud $i$, cela indique qu'il a été infecté avec un temps $t_i \\in ]max\\_obs,maxT[$ dans 20% des $nbsimu$ simulations effectuées. Compléter la méthode ci dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "dV9zdHYPG7Op",
    "outputId": "d75fd0eb-e153-4a40-ebc7-409133a2161b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.      0.77775 0.25711 0.44611 0.23087 0.10976 0.15252 0.09027 0.589\n",
      " 0.36084 0.38563]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def getProbaMC(graph, infections, max_obs, nbsimu=100000):\n",
    "    names, gk, gr = graph\n",
    "    nbNodes = len(names)\n",
    "    rInf = np.array([0]*nbNodes)\n",
    "    for i in range(nbsimu): # lancer nbsimu simulations\n",
    "        sim = simulation(graph, infections, max_obs) \n",
    "        for n in range(nbNodes): \n",
    "            if sim[n] < 10 and sim[n] > max_obs: # si le noeud a été atteint avant maxT dans cette simulation,\n",
    "                rInf[n]+= 1 # augmenter l'effectif des fois où il l'a été\n",
    "    rInf = rInf/nbsimu # ramener évidemment à la valeur moyenne sur toutes les simulations\n",
    "    return (rInf)\n",
    "\n",
    "rInf=getProbaMC(graph,[(0,0)],0)\n",
    "print(rInf)  \n",
    "\n",
    "# Pas de concordance parfaite, mais quelque chose d'assez proche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-sluTACtRCM"
   },
   "source": [
    "Cette méthode permet de bonnes estimations (malgré une certaine variance) lorsque l'on n'a pas d'observations autres que le vecteur d'infections initiales (i.e., on estime des probabilités de la forme: $P(t_i < maxT|\\{t_j\\leq max\\_obs\\})$). Par contre, si l'on souhaite obtenir des probabilités d'infection du type $P(t_i < maxT|\\{t_j\\leq max\\_obs\\}, \\{t_j, j \\in {\\cal O}\\})$, c'est à dire conditionnées à des observations supplémentaires pour un sous-ensembles de noeuds ${\\cal O}$ (avec $t_j > max\\_obs$ pour tout noeud de ${\\cal O}$), l'utilisation de la méthode de MonteCarlo précédente est impossible. Cela impliquerait de filtrer les simulations obtenues selon qu'elles remplissent les conditions sur les noeuds de ${\\cal O}$, ce qui nous amènerait à toutes les écarter sachant que l'on travaille avec des temps continus. \n",
    "\n",
    "Pour estimer ce genre de probabilité conditionnelle, nous allons nous appuyer sur des méthodes de type MCMC, notamment la méthode de Gibbs Sampling. Cette méthode est utile pour simuler selon une loi jointe, lorsqu'il est plus simple d'échantillonner de chaque variable conditionnellement à toutes les autres plutôt que directement de cette loi jointe. L'algorithme est donné par: \n",
    "\n",
    "\n",
    "1.   Tirage d'un vecteur de valeurs initiales pour toutes les variables $X_i$\n",
    "2.   Pour toutes les variable $X_i$ choisies dans un ordre aléatoire, échantillonnage d'une nouvelle valeur: $X_i \\sim p(x_i\\mid x_1,\\dots,x_{i-1},x_{i+1},\\dots,x_n)$\n",
    "3.   Recommencer en 2 tant qu'on souhaite encore des échantillons\n",
    "\n",
    "Notons qu'il est souvent utile d'exploiter la relation suivante, qui indique que pour échantillonner de la loi conditionnelle, il suffit d'échantillonner chaque variable proportionnellement à la loi jointe, avec toutes les autres variables fixées: \n",
    "$$p(x_j\\mid x_1,\\dots,x_{j-1},x_{j+1},\\dots,x_n) = \\frac{p(x_1,\\dots,x_n)}{p(x_1,\\dots,x_{j-1},x_{j+1},\\dots,x_n)} \\propto p(x_1,\\dots,x_n)$$\n",
    "\n",
    "Après une période dite de $Burnin$ d'un nombre d'époques à définir, l'algorithme émet des échantillons qui suivent la loi jointe connaissant les observations. Lorsque l'objectif est d'estimer des probabilités marginales, on fait alors tourner cet algorithme pendant une certain nombre d'époques après la période de $Burnin$, au cours desquelles on recence les différentes affectations de chacune des variables étudiées. \n",
    "\n",
    "Pour mettre en oeuvre cet algorithme, nous aurons aurons besoin d'avoir accès rapidement aux prédecesseurs et successeurs dans le graphe. La méthode ci-dessous retourne un couple de dictionnaires à partir du graphe: \n",
    " \n",
    "\n",
    "*   $preds[i]$  contient la liste des prédécesseurs du  noeud $i$, sous la forme d'une liste de triplets $(j,k_{j,i},r_{j,i})$ pour tous les $j$ précédant $i$ dans le graphe.    \n",
    "*   $succs[i]$  contient la liste des successeurs du  noeud $i$, sous la forme d'une liste de triplets $(j,k_{i,j},r_{i,j})$ pour tous les $j$ pointés par $i$ dans le graphe.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "0sPmzchnSP3r",
    "outputId": "e2b24d9c-1efb-479c-b56d-88652ed68a69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds= {1: [(0, 0.9, 0.2), (8, 0.8, 14)], 0: [(1, 0.9, 3)], 2: [(1, 0.2, 1), (3, 0.4, 0.5)], 3: [(2, 0.5, 0.2), (4, 0.9, 2), (1, 0.5, 2)], 4: [(2, 0.9, 10)], 5: [(2, 0.5, 0.5)], 7: [(5, 0.7, 15), (6, 0.1, 4)], 6: [(1, 0.2, 3)], 8: [(1, 0.8, 0.8)], 9: [(8, 0.2, 0.1), (10, 0.9, 1)], 10: [(1, 0.5, 12)]}\n",
      "succs= {0: [(1, 0.9, 0.2)], 1: [(0, 0.9, 3), (2, 0.2, 1), (3, 0.5, 2), (6, 0.2, 3), (8, 0.8, 0.8), (10, 0.5, 12)], 2: [(3, 0.5, 0.2), (4, 0.9, 10), (5, 0.5, 0.5)], 3: [(2, 0.4, 0.5)], 4: [(3, 0.9, 2)], 5: [(7, 0.7, 15)], 6: [(7, 0.1, 4)], 8: [(9, 0.2, 0.1), (1, 0.8, 14)], 10: [(9, 0.9, 1)]}\n"
     ]
    }
   ],
   "source": [
    "def getPredsSuccs(graph):\n",
    "    names, gk, gr = graph\n",
    "    nbNodes = len(names)\n",
    "    preds = {}\n",
    "    succs = {}\n",
    "    for (a,b),v in gk.items():\n",
    "        s = succs.get(a,[])\n",
    "        s.append((b, v, gr[(a,b)]))\n",
    "        succs[a] = s\n",
    "        p = preds.get(b,[])\n",
    "        p.append((a, v, gr[(a,b)]))\n",
    "        preds[b] = p\n",
    "    return (preds, succs)\n",
    "preds, succs = getPredsSuccs(graph)\n",
    "print(\"preds=\", preds)\n",
    "print(\"succs=\", succs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vk-vCmVX6HtV"
   },
   "source": [
    "Pour calculer les probabilités conditionnelles, il faut prendre en compte les quantités suivantes: \n",
    "\n",
    "\n",
    "*   Probabilité pour $j$ d'être infecté par $i$ au temps $t_j$ connaissant $t_i < t_j$:  \n",
    "$$\\alpha_{i,j}=k_{i,j}r_{i,j} exp(-r_{i,j}(t_j-t_i))$$\n",
    "*   Probabilité pour $j$ de ne pas être infecté par $i$ jusqu'au temps $t$:\n",
    "$$\\beta_{i,j}=k_{i,j} exp(-r_{i,j}(t_j-t_i)) + 1 - k_{i,j}$$\n",
    "*   Probabilité pour $j$ d'être infecté au temps $t_j$ connaissant les prédecesseurs infectés avant $t_j$:\n",
    "$$h_{j}=\\prod_{i \\in preds[j], t_i<t_j} \\beta_{i,j} \\sum_{i \\in preds[i], t_i<t_j} \\alpha_{i,j} / \\beta_{i,j}$$\n",
    "*   Probabilité pour $j$ de ne pas être infecté avant $t_j=maxT$ connsaissant ses prédecesseurs infectés:\n",
    "$$g_{j}=\\prod_{i \\in preds[j], t_i<t_j} \\left(k_{i,j} exp(-r_{i,j}(maxT-t_i)) + 1 - k_{i,j}\\right)=\\prod_{i \\in preds[j], t_i<t_j} \\beta_{i,j}$$\n",
    "\n",
    "A noter que pour tout $i$ tel que $t_i< max\\_obs$, on prend $\\frac{\\alpha_{i,j}}{k_{i,j} exp(-r_{i,j}(max\\_obs-t_i))}$ et $\\frac{\\beta_{i,j}}{k_{i,j} exp(-r_{i,j}(max\\_obs-t_i))}$  dans les définitions de $h_j$ et $g_j$ (donc dans le calcul de la variable $b$ dans la méthode ci-dessous). \n",
    "\n",
    "\n",
    "Dans la méthode $computeab(v, times, preds, max\\_obs)$, on prépare le calcul et les mises à jour de ces quantités. La méthode calcule, pour un noeud $v$ selon les temps d'infection courants donnés dans $times$, deux quantités $a$ et $b$: \n",
    "*   $a= max(1e^{-20}, \\sum_{i \\in preds[v], t_i<t_v} \\alpha_{i,v} / \\beta_{i,v})$ si $t_v< maxT$ et $a=1$ sinon. \n",
    "\n",
    "*   $b=\\sum_{i \\in preds[v], t_i<t_v} \\log \\beta_{i,v}$.\n",
    "\n",
    "Pour les noeuds $i$ tels que $t_i< max\\_obs$, $a=1$ et $b=0$. \n",
    "\n",
    "Compléter la méthode $computeab$ donnée ci-dessous:   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "cOnGCJCBSulp",
    "outputId": "c372babf-0b65-425f-e46c-5ed060e5c8c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0)\n",
      "(1, 0)\n",
      "(0.17610107365772137, -0.17810126145719926)\n",
      "(1, 0)\n",
      "(0.012293749653343879, -0.21077360840944234)\n",
      "(0.012293749653343879, -0.07561333357263278)\n",
      "(1, -1.1230118785518794)\n",
      "(1, -0.5567927090349067)\n"
     ]
    }
   ],
   "source": [
    "eps=1e-20\n",
    "\n",
    "def alpha(i,j,kij,rij,t):\n",
    "    return kij*rij*np.exp(-rij*(t[j]-t[i]))\n",
    "\n",
    "def beta(i,j,kij,rij,t):\n",
    "    return kij*np.exp(-rij*(t[j]-t[i]))+1-kij\n",
    "\n",
    "def beta2(i,j,kij,rij,t,max_obs): # pour gérer le cas où ti < max_obs !\n",
    "    return kij*np.exp(-rij*(max_obs-t[i]))+1-kij\n",
    "\n",
    "def computeab(v, times, preds, max_obs):\n",
    "    preds=preds.get(v,[]) # chercher les prédécesseurs du noeud v\n",
    "    t=times[v] # temps d'infection actuel de v\n",
    "    if t<=max_obs: # si l'infection est survenue avant la date d'observation, \n",
    "        # j'ai la certitude que v est infecté, et la certitude qu'il ne peut pas ne pas l'être : (1,0)\n",
    "        return (1,0)\n",
    "    a = eps\n",
    "    b = 0\n",
    "    if len(preds) > 0: # si v a bien des prédécesseurs\n",
    "        if(t < maxT): # et qu'il est infecté avant la limite\n",
    "            sum_alpha = 0 \n",
    "            for ind in range(len(preds)):\n",
    "                (i,kiv,riv) = preds[ind]\n",
    "                if(times[i]<t):\n",
    "                    sum_alpha += alpha(i,v,kiv,riv,times)/beta(i,v,kiv,riv,times) # simplement appliquer la formule\n",
    "            a = max(eps, sum_alpha)\n",
    "        else:\n",
    "            a = 1\n",
    "        for ind in range(len(preds)):\n",
    "            (i,kiv,riv) = preds[ind]\n",
    "            if(times[i] < max_obs): # cas où il faut apporter un *******correctif******* : explication du pourquoi du comment plus bas.\n",
    "                # tous ont été mis sur la piste par la note un peu obscure qui relie b et hj/gj (\"[...] dans le calcul de la variable b ci-dessous\"), alors même qu'hj et gj n'apparaissaient pas dans la formule\n",
    "                b += np.log(beta(i,v,kiv,riv,times)) - np.log(beta2(i,v,kiv,riv,times,max_obs)) # la clef est dans la soustraction\n",
    "            elif(times[i] < t):\n",
    "                b += np.log(beta(i,v,kiv,riv,times)) # simplement appliquer la formule\n",
    "    return (a,b)\n",
    "\n",
    "nbNodes=len(graph[0])\n",
    "times=np.array([maxT]*nbNodes,dtype=float)\n",
    "times[0]=0\n",
    "times[1]=1\n",
    "times[2]=4\n",
    "#times[3]=10\n",
    "\n",
    "print(computeab(0,times,preds,max_obs=0))\n",
    "print(computeab(0,times,preds,max_obs=2))\n",
    "print(computeab(1,times,preds,max_obs=0))\n",
    "print(computeab(1,times,preds,max_obs=2))\n",
    "print(computeab(2,times,preds,max_obs=0))\n",
    "print(computeab(2,times,preds,max_obs=2)) # voir correctif. ici, selon les résultats attendus, le changement de max_obs doit changer b, \n",
    "                                          # d'où l'intuition de devoir faire quelque chose qui implique max_obs à la formule de b. \n",
    "                                          # sans cela, j'obtenais le même b que pour la ligne précédente, alors que le reste allait.\n",
    "print(computeab(3,times,preds,max_obs=0))\n",
    "print(computeab(3,times,preds,max_obs=2)) # idem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aXnKXCMfLMK-"
   },
   "source": [
    "La méthode $computell$ calcule la log-vraisemblance d'une diffusion (représentée par le tableau times), en appelant la méthode computeab sur l'ensemble des noeuds du réseau. Elle retourne un triplet (log-likelihood, sa, sb), avec $sa$ et $sb$ les tables des valeurs $a$ et $b$ pour tous les noeuds.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "aM0K-VhPUXJn",
    "outputId": "0d61f9f9-4734-4200-b350-393dce314798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll= -13.117139892397578\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "like_indiv= [1.         0.14737154 0.00995741 0.32529856 0.1        0.52489353\n",
      " 0.8        1.         0.20059727 1.         0.5       ]\n"
     ]
    }
   ],
   "source": [
    "def computell(times,preds,max_obs):\n",
    "    sa = np.zeros((len(times)))\n",
    "    sb = np.zeros((len(times)))\n",
    "    for n in range(len(times)): # considérer une diffusion donnée avec les temps associés\n",
    "        a, b = computeab(n, times, preds, max_obs) # créer la matrice des a et b associée\n",
    "        sa[n] = a\n",
    "        sb[n] = b\n",
    "    ll = np.sum(np.log(sa)+sb) # on passe le logarithme de l'exponentielle sous silence.\n",
    "    return ll, sa, sb\n",
    "\n",
    "ll, sa, sb=computell(times,preds,max_obs=0)\n",
    "print(\"ll=\", ll)\n",
    "print(times)\n",
    "print(\"like_indiv=\",np.exp(np.log(sa)+sb)) # petit hint de formule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNlDzJeFNb60"
   },
   "source": [
    "Afin de préparer les mises à jour lors des affectations successives des variables du Gibbs Sampling, on propose de définir une méthode $removeV(v,times,succs,sa,sb)$ qui retire temporairement du réseau un noeud $v$, en passant son temps d'infection à -1 dans times et en retirant sa contribution aux valeurs a et b (contenues dans sa et sb) de tous ses successeurs $j$ tels que $t_j > t_v$ (y compris donc les non infectés qui sont à $t_j=maxT$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "rEGzpS_DaRX5",
    "outputId": "1ff8cc3b-3074-4606-bc73-f5af6e753687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa= [1.         0.17610107 0.01229375 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.        ]\n",
      "sb= [ 0.         -0.17810126 -0.21077361 -1.12301188 -2.30258509 -0.64455983\n",
      " -0.22314355  0.         -1.60645602  0.         -0.69314718]\n",
      "diffa= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "diffb= [0.         0.         0.         1.12301188 0.         0.\n",
      " 0.         0.         0.         0.         0.        ]\n",
      "diffa= [ 0.          0.82389893 -0.01229375  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n",
      "diffb= [0.         0.17810126 0.21077361 0.69314717 0.         0.\n",
      " 0.22314355 0.         1.60645602 0.         0.69314718]\n"
     ]
    }
   ],
   "source": [
    "def removeV(v,times,succs,sa,sb):\n",
    "    succs=succs.get(v,[])\n",
    "    t=times[v]\n",
    "    if t<0:\n",
    "        return \n",
    "    times[v]=-1\n",
    "    sa[v]=1.0\n",
    "    sb[v]=0.0\n",
    "    if len(succs)>0:\n",
    "        c,k,r=map(np.array,zip(*succs))\n",
    "        tp=times[c]\n",
    "        which=(tp>t)\n",
    "\n",
    "        tp=tp[which]\n",
    "        dt=tp-t\n",
    "        k=k[which]\n",
    "        r=r[which]\n",
    "        c=c[which]\n",
    "        rt = -r*dt\n",
    "        b1=k*np.exp(rt)\n",
    "        b=b1+1.0-k\n",
    "\n",
    "        a=r*b1\n",
    "        a=a/b\n",
    "        b=np.log(b)\n",
    "\n",
    "        sa[c]=sa[c]-np.where(tp<maxT,a,0.0)\n",
    "        sa[c]=np.where(sa[c]>eps,sa[c],eps)\n",
    "        sb[c]=sb[c]-b\n",
    "        sb[c]=np.where(sb[c]>0,0,sb[c])\n",
    "\n",
    "#Test\n",
    "print(\"sa=\",sa)\n",
    "print(\"sb=\",sb)\n",
    "\n",
    "nsa=np.copy(sa)\n",
    "nsb=np.copy(sb)\n",
    "ntimes=np.copy(times)\n",
    "removeV(3,ntimes,succs,nsa,nsb)\n",
    "print(\"diffa=\",nsa-sa)\n",
    "print(\"diffb=\",nsb-sb)\n",
    "\n",
    "nsa=np.copy(sa)\n",
    "nsb=np.copy(sb)\n",
    "ntimes=np.copy(times)\n",
    "removeV(1,ntimes,succs,nsa,nsb)\n",
    "print(\"diffa=\",nsa-sa)\n",
    "print(\"diffb=\",nsb-sb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cb8iIMwgO6D9"
   },
   "source": [
    "La méthode addVatT fait l'inverse: elle rajoute un noeud qui était retiré du réseau, avec un temps $newt$. Il faut alors mettre à jour les valeurs a et b (dans sa et sb) de tous les successeurs de $v$ tels que $t_j > newt$ et calculer les valeurs a et b du noeud v. \n",
    "\n",
    "Compléter le code ci-dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "9sDiLiXnngog",
    "outputId": "9ffa4642-7677-45ef-c2bf-2bb6df8b0cf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.830251606174211e-05 8.555487921315824e-05 3.830251606174211e-05 -13.117139892397578\n",
      "0.14737153555403676 2.7755575616098268e-18 0.14737153555403676 -13.117139892397578\n",
      "0.524893534183932 2.999999999999998e-21 0.524893534183932 -13.117139892397578\n"
     ]
    }
   ],
   "source": [
    "def addVatT(v,times,newt,preds,succs,sa,sb,max_obs):\n",
    "    t=times[v]\n",
    "    if t>=0:\n",
    "        raise Error(\"v must have been removed before\")\n",
    "    times[v] = newt\n",
    "    sa[v], sb[v] = computeab(v, times, preds, max_obs) # récupérer les a et b du noeud v : sa case dans sa et sb existe déjà\n",
    "    for i in range(0,len(times)):\n",
    "        if(times[i] > newt): # s'occuper des successeurs de v :\n",
    "            sa[i], sb[i] = computeab(i, times, preds, max_obs) # mettre à jour sa contribution dans leur statut d'information\n",
    "\n",
    "# Tests: \n",
    "nsa=np.copy(sa)\n",
    "nsb=np.copy(sb)\n",
    "c,_,_=map(np.array,zip(*succs[1]))\n",
    "c=np.append(c,1)\n",
    "ll=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(1,times,succs,nsa,nsb)\n",
    "addVatT(1,times,2,preds,succs,nsa,nsb,max_obs=0)\n",
    "ll2=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(1,times,succs,nsa,nsb)\n",
    "addVatT(1,times,1,preds,succs,nsa,nsb,max_obs=0)\n",
    "ll3=np.sum((np.log(nsa)+nsb)[c])\n",
    "llall=np.sum(np.log(nsa)+nsb)\n",
    "print(np.exp(ll),np.exp(ll2),np.exp(ll3),llall)\n",
    "\n",
    "c,_,_=map(np.array,zip(*succs[0]))\n",
    "c=np.append(c,0)\n",
    "ll=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(0,times,succs,nsa,nsb)\n",
    "addVatT(0,times,maxT,preds,succs,nsa,nsb,max_obs=0)\n",
    "ll2=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(0,times,succs,nsa,nsb)\n",
    "addVatT(0,times,0,preds,succs,nsa,nsb,max_obs=0)\n",
    "ll3=np.sum((np.log(nsa)+nsb)[c])\n",
    "llall=np.sum(np.log(nsa)+nsb)\n",
    "print(np.exp(ll),np.exp(ll2),np.exp(ll3),llall)\n",
    "\n",
    "c,_,_=map(np.array,zip(*succs[5]))\n",
    "c=np.append(c,5)\n",
    "ll=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(5,times,succs,nsa,nsb)\n",
    "addVatT(5,times,1,preds,succs,nsa,nsb,max_obs=0)\n",
    "ll2=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(5,times,succs,nsa,nsb)\n",
    "addVatT(5,times,maxT,preds,succs,nsa,nsb,max_obs=0)\n",
    "ll3=np.sum((np.log(nsa)+nsb)[c])\n",
    "llall=np.sum(np.log(nsa)+nsb)\n",
    "print(np.exp(ll),np.exp(ll2),np.exp(ll3),llall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3isBRUNi3JPA"
   },
   "source": [
    "Pour échantillonner pour une variable $i$, il faudra être à même de comparer les vraisemblances selon les différentes affectations. Cela implique de calculer la somme de toutes ces vraisemblances. Mais pour réaliser cette somme, il faudrait que nous sortions de la représentation logarithmique: $\\sum_{t_i} exp(log(p(t_1,\\dots,t_i,\\dots,t_n))$. Si on le fait de cette manière, on risque d'avoir des arrondis à 0 presque partout. Une possibilité (log-sum-exp trick) est d'exploiter la relation suivante:  \n",
    "\n",
    "$$\\log\\sum_i x_i = x^* + \\log\\left( \\exp(x_1-x^*)+ \\cdots + \\exp(x_n-x^*) \\right)$$\n",
    "avec $x^* = \\max{\\{x_1, \\dots, x_n\\}}$\n",
    "\n",
    "Compléter la méthode logsumexp suivante, qui réalise cette somme en évitant les problèmes numériques: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SZuOJI7B3p0O",
    "outputId": "3abe4a23-8999-4612-b06b-ab6b4557f0e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.54045945 -0.67334455] [-3.54045945 -0.67334455]\n"
     ]
    }
   ],
   "source": [
    "def logsumexp(x, axis = -1):\n",
    "    star = np.max(x)\n",
    "    trick = star + np.log(np.sum([np.exp(x[i]-star) for i in range(len(x))], axis)) # juste appliquer la formule\n",
    "    return trick # problèmes numériques évités.\n",
    "\n",
    "# Test: \n",
    "x = np.array([[0.001, 0.02, 0.008], [0.1, 0.01, 0.4]])\n",
    "r = np.log(np.sum(x, -1))\n",
    "x = np.log(x)\n",
    "r2 = logsumexp(x)\n",
    "print(r2, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oqVI0e9T85x-"
   },
   "source": [
    "On souhaite maintenant mettre en place une méthode $sampleV(v,times,newt,preds,succs,sa,sb,max\\_obs,k,k2)$ qui sample un nouveau temps d'infection pour le noeud $v$, connaissant les temps de tous les autres noeuds dans $times$ (ainsi que leurs valeurs $a$ et $b$ correspondantes contenues dans sa et sb). Puisque le domaine de support de $t_v$ est continu, on doit faire quelques approximations en se basant sur une discrétisation des valeurs possibles:\n",
    "\n",
    "\n",
    "1.   On échantillonne $k$ points $d_1,\\dots,d_k$ entre $max\\_obs$ et $maxT$ de manière uniforme, que l'on ordonne de manière croissante. On ajoute $t_v$ à cet ensemble de points pour gagner en stabilité (inséré dans la liste de manière à conserver l'ordre croissant).   \n",
    "2.   On considère chaque point $d_i$ comme le centre d'un bin $[(d_i+d_{i-1})/2,(d_i+d_{i+1})/2]$. Pour $d_1$ on prend $[max\\_obs,(d_i+d_{i+1})/2]$ et pour $d_k$ on prend   $[(d_i+d_{i-1})/2,maxT]$. On fait l'hypothèse que la densité de probabilité est constante sur l'ensemble du bin, que l'on évalue en son centre.   La probabilité que l'on échantillonne dans le bin $i$ est alors égale à: $\\frac{z_i \\times l_i}{\\sum_j z_j \\times l_j + p_{maxT}}$, avec $z_i$ la densité calculée en $d_i$, $l_i$ la taille du bin $i$ et $p_{maxT}$ la probabilité calculée pour $maxT$ (i.e., la probabilité que $v$ ne soit pas infecté dans la diffusion)\n",
    "3.  Si l'indice $i$ samplé de manière proportionnelle aux probabilités calculées à l'étape précédente n'est pas celui de $maxT$, $v$ est alors infecté à un temps inclus dans l'intervale du bin correspondant. Il s'agit alors de re-échantillonner $k2$ points uniformément dans ce bin et de calculer les densités en ces points (pour gagner en stabilité on ajoute le centre du bin $d_i$). Le nouveau temps de $v$ est alors échantillonné proportionnellement à ces densités.\n",
    "\n",
    "Compléter le code ci-dessous:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "K3QmBCRbhkLM",
    "outputId": "766a0e1c-a19a-4c77-e930-852e6493e5d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "  \n",
    "def sampleV(v,times,preds,succs,sa,sb,max_obs,k,k2):\n",
    "    D = np.random.uniform(max_obs, maxT, size = k) # échantillonnage uniforme\n",
    "    D = D + times[v] # plus de stabilité \n",
    "    D = np.sort(D) # trier\n",
    "    L = [max_obs]+list(D)+[maxT]\n",
    "    longueur = []\n",
    "    densite = []\n",
    "    P = []\n",
    "    # calcul de toutes les longueurs et de toutes les densités\n",
    "    for i in range(1, len(L)-1):\n",
    "        longueur.append((L[i]+L[i+1])/2 - (L[i]+L[i-1])/2)\n",
    "        nsa = np.copy(sa)\n",
    "        nsb = np.copy(sb)\n",
    "        ntimes = np.copy(times)\n",
    "        removeV(v, ntimes, succs, nsa, nsb)\n",
    "        addVatT(v, ntimes, L[i-1], preds, succs, nsa, nsb, max_obs)\n",
    "        densite.append((np.log(nsa) + nsb)[v])\n",
    "        \n",
    "    somme = np.array([densite[i]*longueur[i] for i in range(0,len(densite))]).sum()\n",
    "    \n",
    "    # repartir sur le même procédé\n",
    "    nsa = np.copy(sa)\n",
    "    nsb = np.copy(sb)\n",
    "    ntimes = np.copy(times)\n",
    "    removeV(v, ntimes, succs, nsa, nsb)\n",
    "    addVatT(v, ntimes, maxT, preds, succs, nsa, nsb, max_obs)\n",
    "    Pmax = (np.log(nsa)+nsb)[v] # on cherche la probabilité que v ne soit pas infecté dans la diffusion, on a tort ici\n",
    "    P = []\n",
    "    for i in range(1,len(L)-2):\n",
    "        P.append(densite[i]*longueur[i]/(somme+Pmax))\n",
    "    p_c = np.array(P)\n",
    "    for i in range(len(P)):\n",
    "        p_c[i] = np.array(P[:i+1]).sum()\n",
    "    r = np.random.rand()\n",
    "    b = None\n",
    "    for j in range(len(p_c)):\n",
    "        if(r<p_c[j]):\n",
    "            b = j\n",
    "            break\n",
    "        b = len(p_c)\n",
    "    # incomplet\n",
    "    return times[v]\n",
    "\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10) \n",
    "print(times) # il aurait dû se passer quelque chose <<< ici\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Note au lecteur</h3></center>\n",
    "<center><h4>Ce TME a été réalisé en étroite collaboration avec les meilleures volontés de cette promotion, </h4></center>\n",
    "    <center><br>dont celleux parmi nous dont la date de rendu est repoussée à demain.</center>\n",
    "    <center>Il y a fort à parier qu'aucun.e de nous ne s'en serait sorti.e sans cela.</center>\n",
    "    <center>Malheureusement, l'état final de nos encéphales ne nous a pas permis d'aller plus loin.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UCdSA3NF8CrE"
   },
   "source": [
    "Compléter la méthode de Gibbs Sampling $gb$ ci-dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xsnQHVcdjfVT"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "def gb(graph,infections,max_obs,burnin=1000,nbEpochs=10000,k=100,k2=50,freqRecord=1):\n",
    "   #>>>>>>>>>>>>>>>>>>>>>>>\n",
    "   #Votre code ici\n",
    "   #>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "   return rate\n",
    "\n",
    "rate=gb(graph,[(0,0)],0)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iqx6CQ4vQ8rr"
   },
   "source": [
    "# Partie optionnelle\n",
    "\n",
    "L'algorithme de Metropolis-Hastings est une autre méthode de type MCMC qui utilise une distribution d'échantillonnage pour se déplacer dans l'espace des points considérés. Il s'agit de définir une distribution $q(y_{t+1}|x_t)$ de laquelle on sait générer un déplacement. L'algorithme procéde alors de la manière suivante: \n",
    "\n",
    "\n",
    "1.   Générer $y_{t+1}$ selon $q(y_{t+1}|x_t)$ \n",
    "2.   Calculer la probabilité d’acceptation $\\alpha(x_t,y_{t+1})=\\min\\left\\{\\frac{\\pi(y_{t+1})q(x_t,y_{t+1})}{\\pi(x_t)q(y_{t+1},x_t)},1\\right\\} \\,\\!, \\text{ avec } \\pi(x_t) \\text{ la densité de probabilité de } x_t$\n",
    "3.   Prendre $x_{t+1}=\\begin{cases} y_{t+1}, & \\text{avec probabilité}\\,\\,\\alpha \\\\ x_t, & \\text{avec probabilité}\\,\\,1-\\alpha \\end{cases}$\n",
    "\n",
    "\n",
    "\n",
    "Dans notre cas, on propose de travailler avec des déplacements correspondants à des permutations d'un temps d'infection à chaque itération, comme dans le cadre du Gibbs Sampling. A chaque étape on choisit donc une variable à modifier, on choisit un nouveau temps pour cette variable et on calcule la densité correspondante. La probabilité d'acceptation est ensuite calculée selon cette densité et la probabilité du déplacement selon la distribution $q$ qui a servi à générer le nouveau temps d'infection. On se propose de choisir $maxT$ avec une probabilité de 0.1. La probabilité $q(t_v|t)$ pour $t< maxT$ est alors égale  à  $0.9\\times \\frac{1}{maxT-max\\_obs}$.\n",
    "\n",
    "Implémenter l'approche d'échantillonnage par Metropolis-Hasting pour notre problème d'estimation de probabilités marginales d'infection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGoHITZmGxg-"
   },
   "outputs": [],
   "source": [
    "#Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extras : http://mapsi.lip6.fr/pmwiki.php?n=Cours.Semaine8TME8MarkovField"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tme8_mapsi_2019",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
